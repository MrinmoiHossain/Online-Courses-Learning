{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3240, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128, 64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3425, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128, 64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(64, 10),\n",
    "                        nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8142,  0.4013],\n",
      "        [ 1.2131,  0.4736]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6629, 0.1610],\n",
      "        [1.4715, 0.2243]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x000001F37522F438>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6299, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4071,  0.2006],\n",
      "        [ 0.6065,  0.2368]])\n",
      "tensor([[-0.4071,  0.2006],\n",
      "        [ 0.6065,  0.2368]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2915, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(128, 64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(64, 10),\n",
    "                        nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "# Forward pass, get our logits\n",
    "logps = model(images)\n",
    "# Calculate the loss the logits and the labels\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-0.0015, -0.0015, -0.0015,  ..., -0.0015, -0.0015, -0.0015],\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0008, -0.0008, -0.0008,  ..., -0.0008, -0.0008, -0.0008],\n",
      "        ...,\n",
      "        [ 0.0022,  0.0022,  0.0022,  ...,  0.0022,  0.0022,  0.0022],\n",
      "        [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
      "        [ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "loss.backward()\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-0.0233, -0.0130,  0.0236,  ..., -0.0347, -0.0210, -0.0334],\n",
      "        [-0.0247, -0.0226,  0.0114,  ..., -0.0096,  0.0272,  0.0067],\n",
      "        [-0.0122,  0.0064,  0.0317,  ...,  0.0349,  0.0203,  0.0020],\n",
      "        ...,\n",
      "        [-0.0143,  0.0216, -0.0322,  ..., -0.0078, -0.0043, -0.0028],\n",
      "        [-0.0151,  0.0250, -0.0248,  ...,  0.0130, -0.0236,  0.0247],\n",
      "        [ 0.0102,  0.0086,  0.0191,  ..., -0.0248,  0.0142, -0.0224]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[ 0.0037,  0.0037,  0.0037,  ...,  0.0037,  0.0037,  0.0037],\n",
      "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n",
      "        ...,\n",
      "        [ 0.0033,  0.0033,  0.0033,  ...,  0.0033,  0.0033,  0.0033],\n",
      "        [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
      "        [ 0.0012,  0.0012,  0.0012,  ...,  0.0012,  0.0012,  0.0012]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "#Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "#Forward pass, then backward pass, then update weights\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update weights - Parameter containing:\n",
      "tensor([[-0.0233, -0.0130,  0.0236,  ..., -0.0348, -0.0211, -0.0334],\n",
      "        [-0.0247, -0.0226,  0.0114,  ..., -0.0096,  0.0272,  0.0067],\n",
      "        [-0.0123,  0.0064,  0.0317,  ...,  0.0349,  0.0203,  0.0020],\n",
      "        ...,\n",
      "        [-0.0143,  0.0215, -0.0322,  ..., -0.0078, -0.0043, -0.0028],\n",
      "        [-0.0151,  0.0250, -0.0248,  ...,  0.0130, -0.0236,  0.0247],\n",
      "        [ 0.0102,  0.0086,  0.0191,  ..., -0.0248,  0.0142, -0.0224]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "print('Update weights -', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
